{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0b6e94-42ac-475c-b69c-a9cab01064b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "## Step 1: Environment Setup\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6e4ad-5fb9-4efd-b52f-0b71796a7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Data Loading and Processing\n",
    "# Define the function to load JSON file into DataFrame chunks\n",
    "def load_motion_data(json_file, chunk_size=100):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    frames = []\n",
    "    if isinstance(data, list) and isinstance(data[0], list):\n",
    "        for nested_list in data:  # First-level list\n",
    "            for idx, entry in enumerate(nested_list):  # Second-level list\n",
    "                if idx % chunk_size == 0 and idx > 0:\n",
    "                    yield pd.DataFrame(frames)  # Yield the chunk\n",
    "                    frames = []  # Reset frames\n",
    "                if 'keypoints' in entry:\n",
    "                    keypoints = entry['keypoints']\n",
    "                    frame_data = {\n",
    "                        f\"keypoint_{i}_x\": point[0] for i, point in enumerate(keypoints)\n",
    "                    }\n",
    "                    frame_data.update({\n",
    "                        f\"keypoint_{i}_y\": point[1] for i, point in enumerate(keypoints)\n",
    "                    })\n",
    "                    frame_data['timestamp'] = len(frames)\n",
    "                    frames.append(frame_data)\n",
    "            # Yield remaining frames after loop\n",
    "            if frames:\n",
    "                yield pd.DataFrame(frames)\n",
    "    else:\n",
    "        print(f\"Unsupported structure in {json_file}.\")\n",
    "\n",
    "# Define the directory containing the squash-processed JSON files\n",
    "squash_data_dir = '/Users/ishaingersol/Desktop/Dataset/squash-processed/'\n",
    "output_dir = '/Users/ishaingersol/Desktop/Dataset/processed_output/'  # Directory for intermediate outputs\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Function to process a single JSON file in chunks and save the results\n",
    "def process_and_save_file_in_chunks(json_file, output_dir):\n",
    "    file_path = os.path.join(squash_data_dir, json_file)\n",
    "    chunk_idx = 0\n",
    "    for chunk in load_motion_data(file_path):\n",
    "        output_path = os.path.join(output_dir, f\"{json_file.replace('.json', '')}_chunk_{chunk_idx}.csv\")\n",
    "        chunk.to_csv(output_path, index=False)\n",
    "        print(f\"Processed and saved chunk: {output_path}\")\n",
    "        chunk_idx += 1\n",
    "\n",
    "# Process each file individually and save in chunks\n",
    "squash_data_files = [f for f in os.listdir(squash_data_dir) if f.endswith('.json')]\n",
    "print(\"Found JSON files:\", squash_data_files)\n",
    "\n",
    "for json_file in squash_data_files:\n",
    "    process_and_save_file_in_chunks(json_file, output_dir)\n",
    "\n",
    "print(\"All files processed and saved.\")\n",
    "\n",
    "# Combine all processed chunks into a single DataFrame if needed\n",
    "all_motion_data = pd.concat(\n",
    "    [pd.read_csv(os.path.join(output_dir, f)) for f in os.listdir(output_dir) if f.endswith('.csv')],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Display the shape of the DataFrame to confirm data loading\n",
    "print(f\"Loaded DataFrame Shape: {all_motion_data.shape}\")\n",
    "print(\"Sample DataFrame:\")\n",
    "print(all_motion_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b2ec5-52a4-425b-b9db-92c4b9a20d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Keypoints Mapping\n",
    "# Adjust keypoint indices based on supervisor's note\n",
    "keypoint_mapping = {\n",
    "    0: \"Nose\", 1: \"Left Eye Inner\", 2: \"Left Eye\", 3: \"Left Eye Outer\", 4: \"Right Eye Inner\",\n",
    "    5: \"Right Eye\", 6: \"Right Eye Outer\", 7: \"Left Ear\", 8: \"Right Ear\", 9: \"Mouth Left\",\n",
    "    10: \"Mouth Right\", 11: \"Left Shoulder\", 12: \"Right Shoulder\", 13: \"Left Elbow\", 14: \"Right Elbow\",\n",
    "    15: \"Left Wrist\", 16: \"Right Wrist\", 17: \"Left Pinky\", 18: \"Right Pinky\", 19: \"Left Index\",\n",
    "    20: \"Right Index\", 21: \"Left Thumb\", 22: \"Right Thumb\", 23: \"Left Hip\", 24: \"Right Hip\",\n",
    "    25: \"Left Knee\", 26: \"Right Knee\", 27: \"Left Ankle\", 28: \"Right Ankle\", 29: \"Left Heel\",\n",
    "    30: \"Right Heel\", 31: \"Left Foot Index\", 32: \"Right Foot Index\"\n",
    "}\n",
    "\n",
    "# Map additional keypoints up to 132 if needed\n",
    "for idx in range(33, 133):\n",
    "    keypoint_mapping[idx] = f\"Keypoint_{idx}\"\n",
    "\n",
    "# Filter only columns that exist in the DataFrame\n",
    "available_keypoint_columns = [col for col in [f\"keypoint_{idx}_x\" for idx in keypoint_mapping.keys()] + [f\"keypoint_{idx}_y\" for idx in keypoint_mapping.keys()] if col in all_motion_data.columns]\n",
    "if 'timestamp' in all_motion_data.columns:\n",
    "    available_keypoint_columns.append('timestamp')\n",
    "\n",
    "# Extract available keypoint data for visualisation\n",
    "keypoint_data = all_motion_data[available_keypoint_columns]\n",
    "\n",
    "# Rename columns for clarity\n",
    "keypoint_data.rename(columns={\n",
    "    f\"keypoint_{idx}_x\": f\"{name}_x\" for idx, name in keypoint_mapping.items() if f\"keypoint_{idx}_x\" in keypoint_data.columns\n",
    "}, inplace=True)\n",
    "keypoint_data.rename(columns={\n",
    "    f\"keypoint_{idx}_y\": f\"{name}_y\" for idx, name in keypoint_mapping.items() if f\"keypoint_{idx}_y\" in keypoint_data.columns\n",
    "}, inplace=True)\n",
    "\n",
    "# Display sample of the extracted data\n",
    "print(\"Keypoint Data Sample:\")\n",
    "print(keypoint_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d8241-c99e-43ad-8d6e-1724bb224bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Visualisation\n",
    "# Plot motion trajectories of specific keypoints over time\n",
    "def plot_keypoint_motion(data, keypoint_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data['timestamp'], data[keypoint_name], label=keypoint_name, marker='o')\n",
    "    plt.title(f\"Motion Trajectory of {keypoint_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Position Value\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot motion of a specific keypoint\n",
    "plot_keypoint_motion(keypoint_data, \"Right Wrist_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfde01-e74a-47b3-b05e-a0617c2ee728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Basic Motion Analysis\n",
    "# Calculate motion magnitude for a specific keypoint\n",
    "def calculate_motion_magnitude(data, keypoint_name):\n",
    "    data[f\"{keypoint_name}_magnitude\"] = data[keypoint_name].diff().abs()\n",
    "    return data\n",
    "\n",
    "# Example: Analyse motion magnitude of a specific keypoint\n",
    "keypoint_data = calculate_motion_magnitude(keypoint_data, \"Right Wrist_x\")\n",
    "print(\"Motion Magnitude Analysis Sample:\")\n",
    "print(keypoint_data.head())\n",
    "\n",
    "# Additional Steps (to be extended as needed):\n",
    "# - Compare motion data across different files\n",
    "# - Identify patterns corresponding to backhand/forehand movements\n",
    "# - Extend analysis for videos once linked to the motion data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
